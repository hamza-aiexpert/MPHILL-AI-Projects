{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b894b8edf818341"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "#For Loading Data\n",
    "def load_data(data_set):\n",
    "        # Load or define the labels\n",
    "\n",
    "        file_names = {\n",
    "            'training': [\n",
    "                'trainLabels.npy',\n",
    "                'trainAccelerometer.npy',\n",
    "                'trainGravity.npy',\n",
    "                'trainGyroscope.npy',\n",
    "                'trainJinsAccelerometer.npy',\n",
    "                'trainJinsGyroscope.npy',\n",
    "                'trainLinearAcceleration.npy',\n",
    "                'trainMagnetometer.npy',\n",
    "                'trainMSAccelerometer.npy',\n",
    "                'trainMSGyroscope.npy'\n",
    "            ],\n",
    "            'testing': [\n",
    "                'testLabels.npy',\n",
    "                'testAccelerometer.npy',\n",
    "                'testGravity.npy',\n",
    "                'testGyroscope.npy',\n",
    "                'testJinsAccelerometer.npy',\n",
    "                'testJinsGyroscope.npy',\n",
    "                'testLinearAcceleration.npy',\n",
    "                'testMagnetometer.npy',\n",
    "                'testMSAccelerometer.npy',\n",
    "                'testMSGyroscope.npy'\n",
    "            ]\n",
    "        }\n",
    "        data = []\n",
    "        for file_name in file_names[data_set]:\n",
    "            file_path = data_dir + data_set + '/' + file_name\n",
    "            loaded_data = np.load(file_path)\n",
    "            data.append(loaded_data)\n",
    "            print(loaded_data.shape, \"\\t\", file_name)\n",
    "        return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3142216c9418cac4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Main Class for training and testing\n",
    "class ActivityMonitor:\n",
    "    def __init__(self, train_data, test_data, train_labels, test_labels):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.train_labels = train_labels\n",
    "        self.test_labels = test_labels\n",
    "        self.path_save_model = \"ActivityMonitoring/TrainedModels/\"\n",
    "        \n",
    "    def normalize_data(self, data):\n",
    "        reshaped_data = np.reshape(data, (-1, data.shape[2]))\n",
    "        mean = np.mean(data, axis=0)\n",
    "        std = np.std(data, axis=0)\n",
    "        normalized_data = (data - mean) / std\n",
    "        normalized_data = np.reshape(normalized_data, data.shape)\n",
    "        return normalized_data\n",
    "\n",
    "    def resample_data(self, data, target_frequency):\n",
    "        current_frequency = data.shape[1] / 4.0\n",
    "        resampled_data = signal.resample(data, int(data.shape[1] * target_frequency / current_frequency), axis=1)\n",
    "        return resampled_data\n",
    "\n",
    "    def extract_features(self, data):\n",
    "        mean = np.mean(data, axis=1)\n",
    "        std = np.std(data, axis=1)\n",
    "        min_val = np.min(data, axis=1)\n",
    "        max_val = np.max(data, axis=1)\n",
    "        median = np.median(data, axis=1)\n",
    "        kurt = kurtosis(data, axis=1)\n",
    "        skewness = skew(data, axis=1)\n",
    "        features = np.concatenate([mean, std, min_val, max_val, median, kurt, skewness], axis=1)\n",
    "        return features\n",
    "\n",
    "    def process_data(self, data):\n",
    "        sensor_frequencies = {\n",
    "            1: 200,  # Accelerometer\n",
    "            2: 200,  # Gravity\n",
    "            3: 200,  # Gyroscope\n",
    "            4: 20,   # JinsAccelerometer\n",
    "            5: 20,   # JinsGyroscope\n",
    "            6: 200,  # LinearAcceleration\n",
    "            7: 50,   # Magnetometer\n",
    "            8: 67,   # MSAccelerometer\n",
    "            9: 67    # MSGyroscope\n",
    "        }\n",
    "        processed_data = []\n",
    "        for i, d in enumerate(data[1:], start=1):\n",
    "            if i in sensor_frequencies:\n",
    "                target_frequency = 200\n",
    "                resampled_data = self.resample_data(d, sensor_frequencies[i])\n",
    "                normalized_data = self.normalize_data(resampled_data)\n",
    "                extracted_features = self.extract_features(normalized_data)\n",
    "                processed_data.append(extracted_features)\n",
    "            else:\n",
    "                processed_data.append(d)\n",
    "        processed_data.insert(0, data[0])\n",
    "        return processed_data\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        normalized_train = self.process_data(self.train_data)\n",
    "        normalized_test = self.process_data(self.test_data)\n",
    "        train_labels = normalized_train[0]\n",
    "        self.train_data = np.concatenate(normalized_train[1:], axis=1).reshape(len(train_labels), -1)\n",
    "        test_labels = normalized_test[0]\n",
    "        self.test_data = np.concatenate(normalized_test[1:], axis=1).reshape(len(test_labels), -1)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    def calculate_evaluation_metrics(self, true_labels, predicted_labels, set_name):\n",
    "        acc = accuracy_score(true_labels, predicted_labels)\n",
    "        cm = confusion_matrix(true_labels, predicted_labels)\n",
    "        f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "        precision = precision_score(true_labels, predicted_labels, average='weighted', zero_division=1)\n",
    "        recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "        print(\"\\n\")\n",
    "        print(set_name, \"Accuracy:\", acc)\n",
    "        print(set_name, \"Precision:\", precision)\n",
    "        print(set_name, \"F1 Score:\", f1)\n",
    "        print(set_name, \"Recall:\", recall)\n",
    "        print(set_name, \"Confusion Matrix:\\n\", cm)\n",
    "        return acc, cm, f1, precision, recall\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------ \n",
    "    #Random Forest Classifier\n",
    "    def random_forest_classifier(self):\n",
    "        classifier = RandomForestClassifier()\n",
    "        cv_scores = cross_val_score(classifier, self.train_data, self.train_labels, cv=5)\n",
    "        print(\"Cross-validation scores:\", cv_scores)\n",
    "        print(\"Mean CV score:\", np.mean(cv_scores))\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.train_data, self.train_labels, test_size=0.2, random_state=42)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        val_predictions = classifier.predict(X_val)\n",
    "        joblib.dump(classifier,self.path_save_model + \"random_forest_classifier.joblib\")\n",
    "        val_metrics = self.calculate_evaluation_metrics(y_val, val_predictions, \"Validation\")\n",
    "        test_predictions = classifier.predict(self.test_data)\n",
    "        test_metrics = self.calculate_evaluation_metrics(self.test_labels, test_predictions, \"Test\")\n",
    "        return classifier\n",
    "        \n",
    "    #Finding Hyperparameters Random Forest Grid\n",
    "    # def random_forest_grid_search(self):\n",
    "    #     param_grid = {\n",
    "    #         'n_estimators': [100, 200, 300],\n",
    "    #         'max_depth': [None, 5, 10],\n",
    "    #         'min_samples_split': [2, 5, 10]\n",
    "    #     }\n",
    "    #     classifier = RandomForestClassifier()\n",
    "    #     grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "    #     grid_search.fit(self.train_data, self.train_labels)\n",
    "    #     best_classifier = grid_search.best_estimator_\n",
    "    #     print(\"Selected Hyperparameters:\", best_classifier.get_params(), \"\\n\\n\")\n",
    "    #     cv_scores = cross_val_score(best_classifier, self.train_data, self.train_labels, cv=5)\n",
    "    #     print(\"Cross-validation scores:\", cv_scores)\n",
    "    #     print(\"Mean CV score:\", np.mean(cv_scores))\n",
    "    #     X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "    #     best_classifier.fit(self.train_data, self.train_labels)\n",
    "    #     val_predictions = best_classifier.predict(self.X_val)\n",
    "    #     joblib.dump(best_classifier,self.path_save_model + \"random_forest_grid_search.joblib\")\n",
    "    #     val_metrics = self.calculate_evaluation_metrics(self.y_val, val_predictions, \"Validation\")\n",
    "    #     test_predictions = best_classifier.predict(self.test_data)\n",
    "    #     test_metrics = self.calculate_evaluation_metrics(self.test_labels, test_predictions, \"Test\")\n",
    "    #     return best_classifier\n",
    "        \n",
    "    #Random Forest Grid with trained hyperparameters\n",
    "    def random_forest_grid_search_hyperparameters(self):\n",
    "        classifier = RandomForestClassifier(\n",
    "            bootstrap=True,\n",
    "            ccp_alpha=0.0,\n",
    "            class_weight=None,\n",
    "            criterion='gini',\n",
    "            max_depth=None,\n",
    "            # max_features='auto',\n",
    "            max_leaf_nodes=None,\n",
    "            max_samples=None,\n",
    "            min_impurity_decrease=0.0,\n",
    "            min_samples_leaf=1,\n",
    "            min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=300,\n",
    "            n_jobs=None,\n",
    "            oob_score=False,\n",
    "            random_state=None,\n",
    "            verbose=0,\n",
    "            warm_start=False\n",
    "        )\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.train_data, self.train_labels, test_size=0.2, random_state=42)\n",
    "        # Fit the classifier on the training data\n",
    "        classifier.fit(X_train, y_train)\n",
    "        val_predictions = classifier.predict(X_val) \n",
    "        # Save model\n",
    "        joblib.dump(classifier,self.path_save_model + \"random_forest_grid_search_hyperparameters.joblib\")\n",
    "        cv_scores = cross_val_score(classifier, self.train_data, self.train_labels, cv=5)\n",
    "        print(\"Cross-validation scores:\", cv_scores)\n",
    "        print(\"Mean CV score:\", np.mean(cv_scores))\n",
    "        val_metrics = self.calculate_evaluation_metrics(y_val, val_predictions, \"Validation\")\n",
    "        test_predictions = classifier.predict(self.test_data)\n",
    "        test_metrics = self.calculate_evaluation_metrics(self.test_labels, test_predictions, \"Test\")\n",
    "        return classifier\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    #SVM Classifier\n",
    "    def svm_classifier(self):\n",
    "        classifier = SVC()\n",
    "        cv_scores = cross_val_score(classifier, self.train_data, self.train_labels, cv=5)\n",
    "        print(\"Cross-validation scores:\", cv_scores)\n",
    "        print(\"Mean CV score:\", np.mean(cv_scores))\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.train_data, self.train_labels, test_size=0.2, random_state=42)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        val_predictions = classifier.predict(X_val)\n",
    "        joblib.dump(classifier,self.path_save_model + \"svm_classifier.joblib\")\n",
    "        val_metrics = self.calculate_evaluation_metrics(y_val, val_predictions, \"Validation\")\n",
    "        test_predictions = classifier.predict(self.test_data)\n",
    "        test_metrics = self.calculate_evaluation_metrics(self.test_labels, test_predictions, \"Test\")\n",
    "        return classifier\n",
    "    \n",
    "    #Finding Hyperparameters SVM Grid\n",
    "    # def svm_grid_search(self):\n",
    "    #     param_grid = {\n",
    "    #         'C': [0.1, 1, 10],\n",
    "    #         'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "    #         'gamma': [0.1, 1, 'scale']\n",
    "    #     }\n",
    "    #     classifier = SVC()\n",
    "    #     grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "    #     X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "    # \n",
    "    #     grid_search.fit(self.train_data, self.train_labels)\n",
    "    #     best_classifier = grid_search.best_estimator_\n",
    "    #     print(\"Selected Hyperparameters:\", best_classifier.get_params(), \"\\n\\n\")\n",
    "    #     cv_scores = cross_val_score(best_classifier, self.train_data, self.train_labels, cv=5)\n",
    "    #     print(\"Cross-validation scores:\", cv_scores)\n",
    "    #     print(\"Mean CV score:\", np.mean(cv_scores))\n",
    "    #     best_classifier.fit(self.train_data, self.train_labels)\n",
    "    #     val_predictions = best_classifier.predict(self.X_val)\n",
    "    #     joblib.dump(best_classifier,\"ActivityMonitoring/svm_grid_search.joblib\")\n",
    "    #     val_metrics = self.calculate_evaluation_metrics(self.y_val, val_predictions, \"Validation\")\n",
    "    #     test_predictions = best_classifier.predict(self.test_data)\n",
    "    #     test_metrics = self.calculate_evaluation_metrics(self.test_labels, test_predictions, \"Test\")\n",
    "    #     return best_classifier\n",
    "    \n",
    "    #SVM Grid with trained hyperparameters\n",
    "    def svm_grid_search_hyperparameters(self):\n",
    "        classifier = SVC(\n",
    "            C=0.1,\n",
    "            break_ties=False,\n",
    "            cache_size=200,\n",
    "            class_weight=None,\n",
    "            coef0=0.0,\n",
    "            decision_function_shape='ovr',\n",
    "            degree=3,\n",
    "            gamma=0.1,\n",
    "            kernel='linear',\n",
    "            max_iter=-1,\n",
    "            probability=False,\n",
    "            random_state=None,\n",
    "            shrinking=True,\n",
    "            tol=0.001,\n",
    "            verbose=False,\n",
    "        )\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.train_data, self.train_labels, test_size=0.2, random_state=42)\n",
    "        # Fit the classifier on the training data\n",
    "        classifier.fit(X_train, y_train)\n",
    "        val_predictions = classifier.predict(X_val) \n",
    "        # Save model\n",
    "        joblib.dump(classifier,self.path_save_model + \"svm_grid_search_hyperparameters.joblib\")\n",
    "        cv_scores = cross_val_score(classifier, self.train_data, self.train_labels, cv=5)\n",
    "        print(\"Cross-validation scores:\", cv_scores)\n",
    "        print(\"Mean CV score:\", np.mean(cv_scores))\n",
    "        val_metrics = self.calculate_evaluation_metrics(y_val, val_predictions, \"Validation\")\n",
    "        test_predictions = classifier.predict(self.test_data)\n",
    "        test_metrics = self.calculate_evaluation_metrics(self.test_labels, test_predictions, \"Test\")\n",
    "        return classifier\n",
    "        \n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_dir = 'ActivityMonitoring/'\n",
    "    train_data = load_data(\"training\")\n",
    "    test_data = load_data(\"testing\")\n",
    "    train_labels = np.load(data_dir + 'training/trainLabels.npy')\n",
    "    test_labels = np.load(data_dir + 'testing/testLabels.npy')\n",
    "\n",
    "    data_loader = ActivityMonitor(train_data, test_data, train_labels, test_labels)\n",
    "    data_loader.preprocess_data()\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    random_forest_clf = data_loader.random_forest_classifier()\n",
    "    random_forest_clf_grid = data_loader.random_forest_grid_search_hyperparameters()\n",
    "\n",
    "    # SVM Classifier\n",
    "    svm_clf = data_loader.svm_classifier()\n",
    "    svm_grid_clf = data_loader.svm_grid_search_hyperparameters()\n",
    "    \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5ca2607e262d365"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51d02922fa5ad8c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def predict_activity(inp, model_no):\n",
    "    path_save_model = \"ActivityMonitoring/TrainedModels/\"\n",
    "    activity_labels = {\n",
    "        0: \"Bring\",\n",
    "        1: \"Clean Floor\",\n",
    "        2: \"Clean Surface\",\n",
    "        3: \"Close Big Box\",\n",
    "        4: \"Close Door\",\n",
    "        5: \"Close Drawer\",\n",
    "        6: \"Close Lid By Rotate\",\n",
    "        7: \"Close Other Lid\",\n",
    "        8: \"Close Small Box\",\n",
    "        9: \"Close Tap Water\",\n",
    "        10: \"Drink\",\n",
    "        11: \"Dry Off Hands\",\n",
    "        12: \"Dry Off Hands By Shake\",\n",
    "        13: \"Eat Small\",\n",
    "        14: \"Gargle\",\n",
    "        15: \"Getting Up\",\n",
    "        16: \"Hang\",\n",
    "        17: \"Lying Down\",\n",
    "        18: \"Open Bag\",\n",
    "        19: \"Open Big Box\",\n",
    "        20: \"Open Door\",\n",
    "        21: \"Open Drawer\",\n",
    "        22: \"Open Lid By Rotate\",\n",
    "        23: \"Open Other Lid\",\n",
    "        24: \"Open Small Box\",\n",
    "        25: \"Open Tap Water\",\n",
    "        26: \"Plug In\",\n",
    "        27: \"Press By Grasp\",\n",
    "        28: \"Press From Top\",\n",
    "        29: \"Press Switch\",\n",
    "        30: \"Put From Bottle\",\n",
    "        31: \"Put From Tap Water\",\n",
    "        32: \"Put High Position\",\n",
    "        33: \"Put On Floor\",\n",
    "        34: \"Read\",\n",
    "        35: \"Rotate\",\n",
    "        36: \"Rub Hands\",\n",
    "        37: \"Scoop And Put\",\n",
    "        38: \"Sitting Down\",\n",
    "        39: \"Squatting Down\",\n",
    "        40: \"Standing Up\",\n",
    "        41: \"Stand Up From Squatting\",\n",
    "        42: \"Take From Floor\",\n",
    "        43: \"Take From High Position\",\n",
    "        44: \"Take Off Jacket\",\n",
    "        45: \"Take Out\",\n",
    "        46: \"Talk By Telephone\",\n",
    "        47: \"Throw Out\",\n",
    "        48: \"Throw Out Water\",\n",
    "        49: \"Touch Smartphone Screen\",\n",
    "        50: \"Type\",\n",
    "        51: \"Unhang\",\n",
    "        52: \"Unplug\",\n",
    "        53: \"Wear Jacket\",\n",
    "        54: \"Write\"\n",
    "    }\n",
    "    \n",
    "    classifier = joblib.load(path_save_model + \"random_forest_classifier.joblib\")\n",
    "    \n",
    "    if(model_no == \"Random Forest\"):\n",
    "        classifier = joblib.load(path_save_model + \"random_forest_classifier.joblib\")    \n",
    "    elif(model_no == \"Random Forest Grid\"):\n",
    "        classifier = joblib.load(path_save_model + \"random_forest_grid_search_hyperparameters.joblib\")\n",
    "    elif(model_no == \"SVM\"):\n",
    "        classifier = joblib.load(path_save_model + \"svm_classifier.joblib\")\n",
    "    elif(model_no == \"SVM Grid\"):\n",
    "        classifier = joblib.load(path_save_model + \"svm_grid_search_hyperparameters.joblib\")\n",
    "    \n",
    "    #arr = [data_loader.test_data[int(inp), :]]\n",
    "    true_label = inp[0]\n",
    "    arr = inp[1:]\n",
    "\n",
    "    np_arr = np.array(arr)\n",
    "    #print(np_arr.shape)\n",
    "    \n",
    "    prediction = classifier.predict(np_arr.reshape(1, -1))\n",
    "    \n",
    "    #print(prediction[0])\n",
    "        \n",
    "    activity = activity_labels.get(prediction[0])\n",
    "    \n",
    "    print(activity)\n",
    "    true_label_concat = \"Label = \" + str(true_label) + \"\\tActivity = \" + activity_labels.get(true_label)\n",
    "    predicted_label_concat = \"Label = \" + str(prediction[0]) + \"\\tActivity = \" + activity\n",
    "    \n",
    "    return true_label_concat, predicted_label_concat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb8a986ca33da2f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def predict_wrapper(csv_file_path, model):\n",
    "    data = np.genfromtxt(csv_file_path, delimiter=',')    \n",
    "    return predict_activity(data, model)\n",
    "\n",
    "activity_prediction = gr.Interface(\n",
    "    fn=predict_wrapper,  # Pass your function\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload CSV File\"),\n",
    "        #gr.Textbox(type=\"text\", label=\"Model No\", placeholder=\"Enter model to test\")\n",
    "        gr.Radio(choices=[\"Random Forest\", \"Random Forest Grid\", \"SVM\", \"SVM Grid\"], value=\"Random Forest\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(type=\"text\", label=\"True Label\"),\n",
    "        gr.Textbox(type=\"text\", label=\"Prediction\")\n",
    "    ]  # Output component\n",
    ")\n",
    "activity_prediction.launch()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa57a710d58cb58e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
